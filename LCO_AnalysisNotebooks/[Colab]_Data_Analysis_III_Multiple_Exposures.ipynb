{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3u8pGk3AaIm"
      },
      "source": [
        "# Processing Many Exposures and Creating Light Curves\n",
        "\n",
        "In the last tutorial, you learned:\n",
        "\n",
        "* how to measure the calibrated magnitude of a target source in a single exposure\n",
        "* how to make a cutout image of the target source\n",
        "\n",
        "In this tutorial, you will now do these same tasks but for a series of many exposures. The goal here is to measure the calibrated magnitudes of your target for *all* of your observations and plot these magnitudes over time to construct a light curve.\n",
        "\n",
        "You will also make a cutout of the target source in many exposures and stitch these images together to make a .gif to observe how the apparent on-sky brightness of the star changes over time. \n",
        "\n",
        "This notebook requires installing the following Python modules. This should be set up already on the google co-lab platform but if you choose to run this notebook offline, you will require the following modules: \n",
        "* `astropy`\n",
        "* `imageio`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEOPrqp1AaIq"
      },
      "outputs": [],
      "source": [
        "!pip install photutils\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from photutils import Background2D, SExtractorBackground\n",
        "from photutils import DAOStarFinder\n",
        "from photutils import CircularAperture,aperture_photometry\n",
        "from photutils.utils import calc_total_error\n",
        "\n",
        "import astropy.wcs as wcs\n",
        "from astropy.io import fits\n",
        "from astropy.stats import sigma_clipped_stats, SigmaClip\n",
        "from astropy.nddata.utils import Cutout2D\n",
        "from astropy import units as u\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from astropy.visualization import ZScaleInterval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG9YCaG2AaIs"
      },
      "source": [
        "# 0. Define Functions\n",
        "\n",
        "Let's now define two important functions that will allow us to process our data. \n",
        "\n",
        "## Exercise / Question \n",
        "\n",
        "Read through the code below and identify what each of the functions does and add (at least!) a one sentence description as a comment in each code block. If you get stuck, please refer to the Data Analysis II notebook (i.e. the single exposure notebook) for more explanations on these two functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWPRm3zIAaIt"
      },
      "outputs": [],
      "source": [
        "# YOUR DESCRIPTION HERE.\n",
        "\n",
        "def do_phot_get_mag(data,hdr,err,ra,dec):\n",
        "    zpt_instrumental = 25.\n",
        "    w         = wcs.WCS(hdr)\n",
        "    xcoords, ycoords = w.all_world2pix(ra,dec,1)\n",
        "    positions = np.transpose((xcoords, ycoords))\n",
        "    apertures = CircularAperture(positions, r=24.)\n",
        "    phot      = aperture_photometry(data, apertures, error=err)\n",
        "\n",
        "    mag     = list(-2.5*np.log10(phot['aperture_sum']) + zpt_instrumental)\n",
        "    mag_err = list((2.5/np.log(10))*(phot['aperture_sum_err']/phot['aperture_sum']))\n",
        "    \n",
        "    return mag,mag_err\n",
        "\n",
        "\n",
        "# YOUR DESCRIPTION HERE.\n",
        "\n",
        "def make_cutout(data,hdr,ra,dec):\n",
        "\n",
        "    w = wcs.WCS(hdr)\n",
        "    xcoord, ycoord = w.all_world2pix(ra,dec,1)\n",
        "    position = np.transpose((xcoord, ycoord))\n",
        "    size = u.Quantity([120, 120], u.pixel)\n",
        "    cutout = Cutout2D(data, position, size, wcs=w, mode='strict')\n",
        "\n",
        "    cutout_wcs = cutout.wcs\n",
        "    header = cutout_wcs.to_header()\n",
        "    hdu = fits.PrimaryHDU(data=cutout.data, header=header)\n",
        "\n",
        "    return hdu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyO5fBjwAaIu"
      },
      "source": [
        "# 1. Find all exposures\n",
        "\n",
        "In your submission to the TAC you requested observations in two filters, _B_ and _V_. Here, we will start with V-band data. Let's begin by mounting our GDrive:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "q9e9S5nhE1in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next set the path to where the V-band data is stored in your GDrive directory tree:"
      ],
      "metadata": {
        "id": "7yehvlCHE7hp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4WInsiYAaIu"
      },
      "outputs": [],
      "source": [
        "# Set path to data\n",
        "mypath = './drive/MyDrive/LCO/Target_A/V/'\n",
        "outmoviename = 'mymovie.gif'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create a list of *all* the names of the files in this folder (with their file paths):"
      ],
      "metadata": {
        "id": "_zrWsGBXHAtb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlXWtCxtAaIu"
      },
      "outputs": [],
      "source": [
        "# Load in all of the fits images in the directory and sort it\n",
        "\n",
        "image_list = glob.glob(mypath+'*e91.fits.fz')\n",
        "image_list.sort()\n",
        "print(image_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C984oyIAaIv"
      },
      "source": [
        "## Exercise / Question\n",
        "\n",
        "As an exercise below, print the number of filenames in the above list. Is this number equal to the the number of requested observations? \n",
        "\n",
        "Why or why not? ðŸ¤” Discuss with group mates!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p0iKxh1AaIw"
      },
      "outputs": [],
      "source": [
        "# Print the number of files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUkdqsNcAaIw"
      },
      "source": [
        "# 2. Loading in reference star data\n",
        "\n",
        "Next we will set the RA and Dec coordinates for our target and the reference stars that you selected in the single exposure notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMmP3G6KAaIw"
      },
      "outputs": [],
      "source": [
        "# Enter the target star RA and Dec\n",
        "\n",
        "target_RA  = XXX\n",
        "target_DEC = XXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5eja8FQAaIx"
      },
      "outputs": [],
      "source": [
        "# Here, import the lists containing the RA and Dec coordinates for the reference stars you selected\n",
        "\n",
        "ref_ra             = []\n",
        "ref_dec            = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH5sCEReAaIy"
      },
      "outputs": [],
      "source": [
        "# Write down the magnitude of your selected reference stars below in a list\n",
        "\n",
        "ref_mag = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6_lE_SVAaIy"
      },
      "source": [
        "## Exercise / Question\n",
        "\n",
        "Why do you think we use several reference stars instead of one? Write all the reasons you can think of."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sxAwp1dAaIy"
      },
      "outputs": [],
      "source": [
        "# Type up your answers here as comments. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e81iPY8HAaIz"
      },
      "source": [
        "# 3. Visualize the *first* image in the list of images and identify the target and ref. stars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7cziM1YAaIz"
      },
      "outputs": [],
      "source": [
        "# Plot the whole image with the reference star and target star marked to see if it all looks ok\n",
        "\n",
        "# Read in the data\n",
        "sci_data, sci_hdr   = fits.getdata(image_list[0],header=True)\n",
        "\n",
        "# Get the World Coordinate System (WCS) from the fits header. \n",
        "w                            = wcs.WCS(sci_hdr)\n",
        "\n",
        "# Determine where to mark the reference stars in image coordinaes\n",
        "xcoord_ref, ycoord_ref       = w.all_world2pix(ref_ra,ref_dec,1)\n",
        "xcoord_target, ycoord_target = w.all_world2pix([target_RA],[target_DEC],1)\n",
        "\n",
        "# Get the best vmin and vmax to visualize the image\n",
        "interval = ZScaleInterval()\n",
        "vmin     = interval.get_limits(sci_data)[0]\n",
        "vmax     = interval.get_limits(sci_data)[1]\n",
        "print('vmin: ',vmin)\n",
        "print('vmax: ',vmax)\n",
        "\n",
        "# Plot the figure\n",
        "figure = plt.figure(figsize=(12,24))\n",
        "plt.imshow(sci_data, vmin=vmin, vmax=vmax, origin='lower')\n",
        "\n",
        "# Mark with a red circle the target stars. \n",
        "plt.scatter(xcoord_target,ycoord_target,marker='o',\n",
        "            facecolors='none',s=150,linewidth=1,color='red')\n",
        "\n",
        "# Mark with white circles the reference stars. \n",
        "plt.scatter(xcoord_ref,ycoord_ref,marker='o',\n",
        "            facecolors='none',s=150,linewidth=1,color='white')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise / Question\n",
        "\n",
        "Describe what you see in the figure above. What observation is this? When was this data taken and at what LCO site? How might you find out?"
      ],
      "metadata": {
        "id": "iR_UYjuoLq0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code here which answers the above questions"
      ],
      "metadata": {
        "id": "K0c1ZLyPOeII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBNdo3JkAaI0"
      },
      "source": [
        "# 4. Calculate the magnitude of the target star in all B-band frames\n",
        "\n",
        "Read through the code in the cell below and describe what takes place within the `for` loop. \n",
        "\n",
        "Then run the cell. Note: This cell may take a few minutes to run so be patient!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVf6vJGrAaI0"
      },
      "outputs": [],
      "source": [
        "# Make some useful lists of values to track/record\n",
        "\n",
        "obstime = [] # Time needed for x-axis \n",
        "Vmag    = [] # magnitude needed for y-axis\n",
        "Vmag_e  = [] # magnitude error needed for y value error bar\n",
        "\n",
        "# Loop through each frame and calculate and save the required values\n",
        "\n",
        "for frame in image_list:\n",
        "    # 1. Open the frame and read out the data, header and time of observation\n",
        "    sci_data, sci_hdr   = fits.getdata(frame,header=True)\n",
        "    time = sci_hdr['MJD-OBS']\n",
        "    \n",
        "    # Record the time of observation of this frame\n",
        "    obstime.append(time)\n",
        "    \n",
        "    # 2. Get the background of the image and subtract it; \n",
        "    # Calculate the error associated with the background.\n",
        "    sigma_clip = SigmaClip(sigma=3.) # Sigma clip bright obvious things to avoid biasing the background estimate\n",
        "    bkg_estimator = SExtractorBackground() # Apply the SExtractor algorithm to our estimation\n",
        "    bkg = Background2D(\n",
        "        sci_data, (50, 50),\n",
        "        filter_size=(3, 3),\n",
        "        sigma_clip=sigma_clip,\n",
        "        bkg_estimator=bkg_estimator)\n",
        "\n",
        "    # Now let's subtract the background from the data\n",
        "    sci_bkg = sci_data - bkg.background\n",
        "\n",
        "    # Define an error image that will be used when calculating photometry\n",
        "    effective_gain = 1.\n",
        "    error = calc_total_error(sci_bkg, bkg.background_rms, effective_gain)\n",
        "    \n",
        "    # 3. For the target star and each reference star, carry out photometry. \n",
        "    # Be sure to use the background subtracted image. \n",
        "    # This step should output an error of the photmetry measurement. \n",
        "    \n",
        "    # Calculate instrumental mags for each of the reference stars\n",
        "    ref_instr_mag,ref_instr_mag_err = do_phot_get_mag(sci_bkg,sci_hdr,error,ref_ra,ref_dec)\n",
        "\n",
        "    # Do photometry on the variable target\n",
        "    tar_mag,tar_mag_err = do_phot_get_mag(sci_bkg,sci_hdr,error,target_RA,target_DEC)\n",
        "    \n",
        "    # 4. Find the magnitude offset between the reference stars \n",
        "    # and the catalog magnitudes \n",
        "    # and calculate the magnitude of the target star, and its error. \n",
        "    \n",
        "    # Calculate offsets and the standard deviation of the offset from each star.\n",
        "    offsets = []\n",
        "    for i in range(len(ref_instr_mag)):\n",
        "        offsets.append(ref_mag[i] - ref_instr_mag[i])\n",
        "    offset = np.mean(offsets)\n",
        "    offset_err = np.std(offsets)\n",
        "\n",
        "    cal_tar_mag = tar_mag[0]+offset\n",
        "    cal_tar_mag_err = np.sqrt(tar_mag_err[0]**2.+offset_err**2.)\n",
        "    \n",
        "    Vmag.append(cal_tar_mag)\n",
        "    Vmag_e.append(cal_tar_mag_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVMWMXxJAaI1"
      },
      "source": [
        "## Exercise / Question\n",
        "\n",
        "Next we'll use `pandas` to create a new dataframe/table to house your results contained within the `obstime`, `Vmag`, and `Vmag_err` lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELpAZbhVAaI1"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "import pandas as pd\n",
        "  \n",
        "# We call the DataFrame constructor after zipping\n",
        "# the three lists, with columns specified\n",
        "results_df = pd.DataFrame(list(zip(obstime, Vmag, Vmag_e)),\n",
        "               columns =['Observation Time', 'Vmag', 'Vmag_err'])\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's often helpful to output our results to a .csv file. Read through the documentation for the `pandas` function `.to_csv` and write a command below which outputs this new table of results to a .csv file.\n",
        "\n",
        "The documentation for this can be found [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)."
      ],
      "metadata": {
        "id": "eixJfOWuU7WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Ir6pFFdyVkCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J93gWVIwAaI2"
      },
      "source": [
        "# Making a Light Curve\n",
        "\n",
        "It's now time to plot out these results! ðŸ™Œ\n",
        "\n",
        "## Exercise / Question\n",
        "\n",
        "In a code cell below, write some code which creates a figure which plots the evolution of the magnitude of the star in V-band over time.\n",
        "\n",
        "Make sure you label the axes and plot out the error for each datapoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuViSD2KAaI3"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydUZ8ZW3AaI3"
      },
      "source": [
        "# 5. Constructing Cutouts\n",
        "\n",
        "## Exercise / Question\n",
        "\n",
        "Read through the code in the cell below and describe what takes place within the `for` loop. \n",
        "\n",
        "Then run the cell. Note: This cell may take a few minutes to run so be patient!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuMIMHcOAaI3"
      },
      "outputs": [],
      "source": [
        "# Loop through each frame and calculate and save the required image\n",
        "\n",
        "for frame in image_list:\n",
        "    # 1. Open the frame and read out the data, header and time of observation\n",
        "    # Read in file\n",
        "    hdu = fits.open(frame)\n",
        "\n",
        "    # Grab the actual science data based on above.\n",
        "    sci_data = hdu[1]\n",
        "    sci_hdr = sci_data.header\n",
        "    time = sci_hdr['MJD-OBS']\n",
        "    \n",
        "    # Record the time of observation of this frame\n",
        "    obstime.append(time)\n",
        "    \n",
        "    # 2. Get the background of the image and subtract it; \n",
        "    # Calculate the error associated with the background.\n",
        "    sigma_clip = SigmaClip(sigma=3.) # Sigma clip bright obvious things to avoid biasing the background estimate\n",
        "    bkg_estimator = SExtractorBackground() # Apply the SExtractor algorithm to our estimation\n",
        "    bkg = Background2D(\n",
        "        sci_data.data, (50, 50),\n",
        "        filter_size=(3, 3),\n",
        "        sigma_clip=sigma_clip,\n",
        "        bkg_estimator=bkg_estimator)\n",
        "\n",
        "    # Now let's subtract the background from the data\n",
        "    sci_bkg = sci_data.data - bkg.background\n",
        "\n",
        "    # Make tiny cutouts of the variable star in each frame\n",
        "    cutout_hdu = make_cutout(sci_bkg,sci_hdr,target_RA,target_DEC)\n",
        "    #cutout_hdu.writeto(frame+'_cutout.fits', overwrite=True)\n",
        "\n",
        "    # Plot figures using these cutouts and output images\n",
        "    interval = ZScaleInterval()\n",
        "    vmin = interval.get_limits(cutout_hdu.data)[0]\n",
        "    vmax = interval.get_limits(cutout_hdu.data)[1]\n",
        "\n",
        "    plt.subplot(projection=wcs.WCS(cutout_hdu.header))\n",
        "    plt.imshow(cutout_hdu.data, vmin=vmin, vmax=vmax, origin='lower')\n",
        "    plt.xlabel('R.A.')\n",
        "    plt.ylabel('Declination')\n",
        "\n",
        "    # Save the small cutout as a png, with the file name as the time of observation. \n",
        "    # This can be used later to make a movie of your source\n",
        "    pngname = str(time).replace('.','')\n",
        "    plt.savefig(mypath+pngname+'.png', overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydHDcDGhAaI4"
      },
      "source": [
        "# Making a movie!\n",
        "\n",
        "As a final step, let's stitch these images together to make a mini movie of your target and it's varying brightness on the night sky."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frbRN51PAaI4"
      },
      "outputs": [],
      "source": [
        "# Here we are going to use the cutouts we made above to make\n",
        "# an little movie of the variable star target changing brightness\n",
        "# over time and loop it!\n",
        "\n",
        "import imageio \n",
        "\n",
        "cutout_list = glob.glob(mypath+'*.png')\n",
        "cutout_list.sort()\n",
        "\n",
        "cutout_frames = []\n",
        "for file in cutout_list:\n",
        "    cutout_frames.append(imageio.imread(file))\n",
        "imageio.mimsave(mypath+'mymovie.gif', cutout_frames)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrapping Up\n",
        "\n",
        "And.. that's it! Congratulations on completing the data analysis portion of the PASEA-ARP Program! ðŸŽ‰ðŸ¥³\n",
        "\n",
        "The next step will be to work with your group mates to prepare a presentation on your findings. More details on this will be found on Slack!"
      ],
      "metadata": {
        "id": "1-tAzErxr34S"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}